{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Science - Machine Learning Methods\n",
    "\n",
    "Some of the examples and exercises of this course are based on two popular books on data science with Python, [Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)\n",
    "and [the Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/).\n",
    "\n",
    "<span><img src=\"images/HandsonML.jpg\" width=\"200\" /><img src=\"images/PDSH-cover.png\" width=\"200\" /></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dimension Reduction Methods\n",
    "\n",
    "This modcule covers the process to transform data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its intrinsic dimension. This process is called dimensionality reduction. The space of the new features is also called the projection space. We will cover 2 commonly used dimensionality reduction methods.\n",
    "\n",
    "1. Principal Component Analysis (PCA)\n",
    "2. T-SNE\n",
    "\n",
    "[<img src=\"images/colab-badge.png\" width=\"200\"/>](https://colab.research.google.com/github/jtao/AdvancedML/blob/main/Dimension_Reduction_methods.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Curse of Dimensionality\n",
    "Most traditional machine learning methods break down in high dimensions, and this phenomenon is commonly referred to as the curse\n",
    "of dimensionality. The reason for this phenomenon is shown in the following discussion.\n",
    "\n",
    "> Consider a p-dimensional unit hypercube $[0,1]^p$ whose volume is 1. For a given target point, the volume of the hypercubical neighborhood of this point with the edge length $r$ is $S = r^d$. Then if we uniformly sample $N$ observations from it, to include a fraction S of the observations in the hypercubical neighborhood of a target point, the expected edge length will be $e_p(r) = S^{1/p}$.\n",
    "\n",
    "* When $p=10$ and $S = 0.1$, $e_{10}(r) \\approx 0.80$. Recall that the entire range for each dimension is only 1, it means that to capture 10% of the data to form a local average, we must cover 80% of the range of each input variable. **Such neighborhoods are no longer “local.”**\n",
    "* Another manifestation is that, when $p$ is big, the sampling density is proportional to $N^{1/p}$. If $N = 10$ represents a dense sample for a single input problem, then $N^{10} = 10^{10}$ is the sample size required for the same sampling density with 10 inputs. **Thus in high-dimensional settings, all feasible training samples sparsely populate the input space.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "1. We build a simulaiton study to show the above discussion. For $p$ from 1 to 10, we random sample $N = 10$ observations uniformly from the p-dimensional unit hypercube $[0,1]^p$ respectively. For each observation, we calculate the distance from its nearest neighbor. The average distances of all $N = 10$ observations for different $p$ are shown in the plot below.\n",
    "\n",
    "> We observe that when $N$ is fixed, the average distance to the nearest neighbor increases as $p$ increases. The points are not close to each other for a large $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 1692,
     "status": "ok",
     "timestamp": 1616540997876,
     "user": {
      "displayName": "Xiaomeng Yan",
      "photoUrl": "",
      "userId": "11420231255337685715"
     },
     "user_tz": 300
    },
    "id": "k_PaD2EwfCmi",
    "outputId": "2d0c8ed4-c233-4977-e681-f90e73d1fbdf",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "N = 10\n",
    "ndist = np.zeros(10)\n",
    "for p in range(10):\n",
    "    X = np.random.uniform(low=0.0, high=1.0,size=[N,p+1])\n",
    "    nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X)  \n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "    ndist[p] = np.mean(distances[:,1])  # The first neighbor is the observation itself. The second neighbor is what we want.\n",
    "\n",
    "plt.plot(range(1,11), ndist,'.-',markersize = 12)\n",
    "plt.xlabel('Dimension')\n",
    "plt.ylabel('Average Distance to Nearest Neighbor')\n",
    "plt.title('Distance to 1-NN vs. Dimension (Sampe Size = 10)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omox_e5Q05Ml",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2) We now fix $p = 10$ and set $N$ as 10, 100, 1000, or 10000. The average distances to the nearest neighbor of all observations for different $N$ are shown in the plot below. \n",
    "\n",
    "> We observe that when $N$ increases to 10000, the average distance for $p=10$ is around 0.4, which is still higher than the values of $p=1,2,3$ with $N = 10$. This shows that decreasing the number of features is more effective than increasing the number of samples to solve the curse of high dimensionality. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 4643,
     "status": "ok",
     "timestamp": 1616541000846,
     "user": {
      "displayName": "Xiaomeng Yan",
      "photoUrl": "",
      "userId": "11420231255337685715"
     },
     "user_tz": 300
    },
    "id": "8k5Gzv5s199h",
    "outputId": "342b9f4d-c8c3-4b40-b1ca-6502a02a6a77",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0) # fix random seed\n",
    "N = 10\n",
    "p = 10\n",
    "ndist2 = np.zeros(4)\n",
    "for Np in range(4):\n",
    "    X = np.random.uniform(low=0.0, high=1.0,size=[N**(Np+1),p])\n",
    "    nbrs2 = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X)\n",
    "    distances2, indices2 = nbrs2.kneighbors(X)\n",
    "    ndist2[Np] = np.mean(distances2[:,1])\n",
    "\n",
    "plt.plot(range(1,5), ndist2,'.-',markersize = 12)\n",
    "plt.xticks(range(1,5), (10,100,1000,10000))\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('Average Distance to Nearest Neighbor')\n",
    "plt.title('Distance to 1-NN vs. Sample Size (Dimension = 10)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2lLQxj8-G6Y",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Principal Component Analysis (PCA)\n",
    "#### Methodology of PCA\n",
    "\n",
    "**Principal Component Analysis (PCA)** identifies the linear combinations of features that account for **the most variance** in the data. These linear combinations are called the Principal Components (PCs). PCA is one of the most popular linear dimensionality reduction methods.\n",
    "\n",
    "> **Definition (Linear Dimensionality Reduction)** Give a $d$-dimensional feature vector $\\mathbf{x} \\in \\mathbb{R}^{d}$ and a choice of dimensionality $r < d$. An linear transformation $f: \\mathbb{R}^d \\rightarrow \\mathbb{R}^r$ can be represented by a transformation matrix $\\mathbf{V} \\in \\mathbb{R}^{d\\times r}$ that $\\mathbf{y} = f(\\mathbf{x}) =  \\mathbf{V}^T\\mathbf{x} $, where $\\mathbf{y} \\in \\mathbb{R}^{r}$ is called  the transformed feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Denote the $N$ observations of $\\mathbf{x}$ by $\\mathbf{x}^1, \\mathbf{x}^2, \\dots, \\mathbf{x}^N$, and $\\mathbf{X} = (\\mathbf{x}^1, \\mathbf{x}^2, \\dots, \\mathbf{x}^N)^T \\in \\mathbb{R}^{N\\times d}$ is the data matrix. Then the transformed data with linear transformation $f$ will be $\\mathbf{Y} = \\mathbf{X}\\mathbf{V} \\in \\mathbb{R}^{N\\times r}$.\n",
    "\n",
    "To begin with, we consider to generate only one feature with $r=1$.\n",
    "Then, $\\mathbf{V}$ becomes a transformation vector (denoted by $\\mathbf{v}$), and the transformed $N \\times 1$ data is $\\mathbf{y}_1 = \\mathbf{X}\\mathbf{v}$. \n",
    "\n",
    "The first step of PCA is to center each column \n",
    "of $\\mathbf{X}$ to make sure that $\\mathbf{1}^T\\mathbf{X} = \\sum_{i=1}^N (\\mathbf{x}^{i})^T = \\mathbf{0}^T$. As a result, the sample mean of the transformed feature is also 0 since $\\frac{1}{N}\\mathbf{1}^T\\mathbf{y}_1 = \\frac{1}{N}\\mathbf{1}^T\\mathbf{X}\\mathbf{v} = \\frac{1}{N}\\mathbf{0}^T\\mathbf{v} = 0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "PCA then finds $\\mathbf{v}$ which maximizes the sample variance of the transformed feature:\n",
    "> $\\max_{\\mathbf{v}} \\mathbf{y}_1^T\\mathbf{y}_1 = \\max_{\\mathbf{v}} \\mathbf{v}^T\\mathbf{X}^T\\mathbf{X}\\mathbf{v}$ subject to $\\mathbf{v}^T\\mathbf{v} = 1$,\n",
    "\n",
    "where $\\mathbf{v}^T\\mathbf{v} = 1$ is used to control the scale of $\\mathbf{v}$. The solution of the above optimization problem is denoted as $\\mathbf{v}_1$. Then the transformed feature $\\mathbf{y}_1 = \\mathbf{X}\\mathbf{v}_1$ is called the first PC of $\\mathbf{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we consider the case when $r>1$. After $\\mathbf{v}_1$ and $\\mathbf{y}_1$ are obtained, we can find the next PC (the next transformed feature) $\\mathbf{y}_2 = \\mathbf{X}\\mathbf{v}_2$ where $\\mathbf{v}_2$ is the solution of:\n",
    "\n",
    "> $\\max_{\\mathbf{v}} \\mathbf{v}^T\\mathbf{X}^T\\mathbf{X}\\mathbf{v}$ subject to $\\mathbf{v}^T\\mathbf{v} = 1$ and $\\mathbf{v}^T\\mathbf{v}_1 = 0$.\n",
    "\n",
    "where $\\mathbf{v}^T\\mathbf{v}_1 = 0$ requires that the new $\\mathbf{v}$ should be orthogonal to $\\mathbf{v}_1$. \n",
    "\n",
    "In the similar way, we can solve $\\mathbf{v}_3,\\dots,\\mathbf{v}_r$ sequantially with the additional constraint that when solving $\\mathbf{v}_i$ ($i = 3,\\dots r$), $\\mathbf{v}_i$ should be orthogonal to $\\mathbf{v}_1,\\dots,\\mathbf{v}_{i-1}$. Then the transformation matrix is $\\mathbf{V} = (\\mathbf{v}_1, \\mathbf{v}_2,\\dots, \\mathbf{v}_r$). The transformed data is $\\mathbf{Y} = \\mathbf{X}\\mathbf{V}$ which contains the first $r$ PCs of the original data. At most, we can generate $r = \\text{rank}(\\mathbf{X})$ PCs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SA5aNtRYyW0a",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### PCA is related to the **singular value decomposition (SVD)**.\n",
    "\n",
    "The SVD is a matrix factorization/decomposition method. Specifically, the SVD of an $ N\\times p$ real matrix $\\mathbf{X}$ is a factorization of the form:\n",
    "\n",
    "> $\\mathbf{X} = \\mathbf{U}\\boldsymbol{\\Sigma}\\mathbf{V}^T$.\n",
    "\n",
    "* $\\mathbf{U} \\in \\mathbb{R}^{N \\times N}$ and $\\mathbf{V} \\in \\mathbb{R}^{p \\times p}$ are orthogonal matrices that $\\mathbf{U}^T\\mathbf{U} = \\mathbf{U}\\mathbf{U}^T = \\mathbf{I}$ and $\\mathbf{V}^T\\mathbf{V} = \\mathbf{V}\\mathbf{V}^T = \\mathbf{I}$\n",
    "* $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{N \\times p}$ is a rectangular diagonal matrix with non-negative real numbers on the diagonal. The diagonal entries $\\sigma_i = \\Sigma_{ii}$ are known as the singular values of $\\mathbf{X}$. \n",
    "* The columns of $\\mathbf{U}$ and the columns of $\\mathbf{V}$ are called the left-singular vectors and right-singular vectors of $\\mathbf{X}$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are several properties:\n",
    "\n",
    "(1) **The solution of $\\mathbf{v}_i$ when constructing the $i$th PC is the same as the right-singular vector of $\\mathbf{X}$ corresponding to the $i$th largest singular value.** As a result, PCA can be solved by the SVD.\n",
    "\n",
    "(2) The sample variance of the $i$th PC is $\\mathbf{y}_i^T\\mathbf{y}_i = \\sigma_i^2$. Then $\\frac{\\sigma_i^2}{\\sum_{i=1}^N \\sigma_i^2} = \\frac{ \\mathbf{y}_i^T\\mathbf{y}_i}{\\sum_{i=1}^N\\mathbf{y}_i^T\\mathbf{y}_i} = \\frac{\\mathbf{y}_i^T\\mathbf{y}}{\\sum_{i=1}^N\\mathbf{x}_i^T\\mathbf{x}_i}$ is called the percentage of variance explained by the $i$th PC. $\\mathbf{x}_i$ here represents the centered $\\mathbf{x}_i$. $\\frac{\\sum_{i=1}^r\\sigma_i^2}{\\sum_{i=1}^N \\sigma_i^2}$ is called the percentage of variance explained by the first $r$ PCs.\n",
    "\n",
    "(3) For any two PCs $\\mathbf{y}_i$ and $\\mathbf{y}_j$ with $i \\neq j$, $\\mathbf{y}_i^T\\mathbf{y}_j = 0$. This means that every two PCs are orthogonal to each other.\n",
    "\n",
    "> Proof: $\\mathbf{y}_i = \\mathbf{X}\\mathbf{v}_i = \\mathbf{U}\\boldsymbol{\\Sigma}\\mathbf{V}^T\\mathbf{v}_i = \\mathbf{U}\\boldsymbol{\\Sigma} \\mathbf{e}_i^T = \\sigma_{i}\\mathbf{u}_i$, where $\\mathbf{e}_i$ is the basis vector with the $i$th entry equal to 1 and the other entries equal to 0. Then $\\mathbf{y}_i^T\\mathbf{y}_j = \\sigma_{i}\\sigma_{j}\\mathbf{u}_i^T\\mathbf{u}_j = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqFRf77dxswc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example 1: Image compression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_awOit5x2CC"
   },
   "outputs": [],
   "source": [
    "vizlogo_path = \"https://github.com/jtao/VIST271/raw/main/images/viz_logo.png\"\n",
    "vizlogo = \"viz_logo.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3gZ1zqRyXmp"
   },
   "source": [
    "# Read Image\n",
    "\n",
    "We first download an image from a URL and then open it with the Image.open function in PIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSGF5ASHxI0i"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter, ImageDraw, ImageFont, ImageOps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "eo7aIDv6ydQa",
    "outputId": "21edcd82-3f67-4e6b-945b-775f431fc24b"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from PIL import Image\n",
    "urllib.request.urlretrieve(vizlogo_path, vizlogo)\n",
    "viz = Image.open(vizlogo)\n",
    "viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gu3VMqd9ynfJ",
    "outputId": "047a8611-fabe-4ac3-e1eb-38e4f12dd0f7"
   },
   "outputs": [],
   "source": [
    "viz.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNnEp3BrzmWX"
   },
   "source": [
    "PNG images usually have four channels. Three color channels for red, green and blue, and the fourth channel is for transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "eKTGklOpy1is",
    "outputId": "4b11b51e-8591-4f2e-8c82-8db76584f2bf"
   },
   "outputs": [],
   "source": [
    "viz.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7etQLSmIy2n8",
    "outputId": "2d726c65-48c7-4d2b-c3d3-cbb99dc4918a"
   },
   "outputs": [],
   "source": [
    "viz.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qw7oqQiz3qFC"
   },
   "source": [
    "Let's convert it into a grayscale image so that we only need to deal with one channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dg_mhig2y3_k"
   },
   "outputs": [],
   "source": [
    "viz = ImageOps.invert(viz.convert('L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "CdRRhevL3zNk",
    "outputId": "0c322565-61ca-4692-923c-d005624e224e"
   },
   "outputs": [],
   "source": [
    "viz.mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46cezJki38Gj"
   },
   "source": [
    "Let's make the image very small so that we could print out the grayscale values of each pixel and compare those against the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olcJlAV2y6yK"
   },
   "outputs": [],
   "source": [
    "viz = viz.resize((round(viz.size[0]*0.05), round(viz.size[1]*0.05)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xvPukyFWzAkK",
    "outputId": "3b527975-40f4-48ce-e010-78a02e0016f8"
   },
   "outputs": [],
   "source": [
    "viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUeNsOZJ2miR"
   },
   "outputs": [],
   "source": [
    "viz_mat= np.asarray(viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uodCacDt2qKe",
    "outputId": "0a473d20-13c4-4482-c27e-dfcab3cb1892"
   },
   "outputs": [],
   "source": [
    "viz_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "injT7S7z2tTc",
    "outputId": "60808f6d-d061-4a8d-d1ad-c7dd727bf0c2"
   },
   "outputs": [],
   "source": [
    "print(viz_mat-255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zG1MiQzD5Xra"
   },
   "source": [
    "What happens when we resize it back?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "cnyYuvfx4rDg",
    "outputId": "0e64779b-7323-47a2-eda8-62bdf5f27217"
   },
   "outputs": [],
   "source": [
    "viz = viz.resize((round(viz.size[0]*20), round(viz.size[1]*20)))\n",
    "viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZRJ9fVK5pAG"
   },
   "source": [
    "Let's reload the image and convert it into grayscale for more operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "_UdIaDlm5La4",
    "outputId": "6c93695a-ec83-4246-95bf-548ccbc2eef7"
   },
   "outputs": [],
   "source": [
    "viz = Image.open(vizlogo)\n",
    "viz = ImageOps.invert(viz.convert('L'))\n",
    "viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uG2oNmkI-sOp",
    "outputId": "212a7057-ad64-4ba2-8b6e-d6d174132209"
   },
   "outputs": [],
   "source": [
    "viz.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFfp8Yc_5n9U"
   },
   "outputs": [],
   "source": [
    "viz_mat = np.asarray(viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "quOmSuLy53Nc",
    "outputId": "4313bc6a-f7c6-40b2-a40b-cd6b92cfc8d5"
   },
   "outputs": [],
   "source": [
    "viz_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaYuDgvn6Jud"
   },
   "source": [
    "Let's make sure that we can directly plot the array with the PIL library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "Fe4fgxc753sL",
    "outputId": "34f27ac4-4f99-4689-8640-449d3ed1b943"
   },
   "outputs": [],
   "source": [
    "Image.fromarray(viz_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnFme-MXesQj"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def plot_pca(mat, n):\n",
    "  fig, axes = plt.subplots(n,n, figsize=(15, 15))\n",
    "  for i, ax in enumerate(axes.flat):\n",
    "    pca = PCA(i).fit(mat) \n",
    "    img_transformed = pca.transform(mat) \n",
    "    ax.set(xticks=[], yticks=[], xlabel=\"# of PCs: %d, Ratio: %6.4f\"%(i+1, np.sum(pca.explained_variance_ratio_)*100))\n",
    "    temp = pca.inverse_transform(img_transformed) \n",
    "    ax.imshow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "id": "fr8aaQT3gRIQ",
    "outputId": "f5efdb84-ec95-442e-9b9f-5473b30e4b6a"
   },
   "outputs": [],
   "source": [
    "plot_pca(viz_mat, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqFRf77dxswc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example 2: Iris dataset\n",
    "\n",
    "The Iris dataset in sklearn.datasets represents 3 kinds of Iris flowers (Setosa, Versicolour, and Virginica) with 4 attributes: sepal length, sepal width, petal length, and petal width. Here we plot different observations on the first 2 principal components. The color of each point in the plot reflects its kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "executionInfo": {
     "elapsed": 961,
     "status": "ok",
     "timestamp": 1616541012851,
     "user": {
      "displayName": "Xiaomeng Yan",
      "photoUrl": "",
      "userId": "11420231255337685715"
     },
     "user_tz": 300
    },
    "id": "XdPg1Mpx-GYo",
    "outputId": "15a7799a-9678-4862-e346-dda27081b904",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data # 4 columns, each column for one feature.\n",
    "y = iris.target\n",
    "target_names = iris.target_names\n",
    "\n",
    "## run PCA with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "colors = ['navy', 'turquoise', 'darkorange']\n",
    "lw = 2\n",
    "\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "    plt.scatter(X_r[y == i, 0], X_r[y == i, 1], color=color, alpha=.8, lw=lw, label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA of IRIS dataset')\n",
    "\n",
    "plt.figure();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzt9dYDE8heI",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example 3: Labeled Faces\n",
    "\n",
    "The Wild dataset includes several thousand collated photos of various public figures, and we use the Labeled Faces figures as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28286,
     "status": "ok",
     "timestamp": 1616541042948,
     "user": {
      "displayName": "Xiaomeng Yan",
      "photoUrl": "",
      "userId": "11420231255337685715"
     },
     "user_tz": 300
    },
    "id": "MrrF2Ougxr5O",
    "outputId": "f459badf-ecff-4794-98e8-5f9628d48ce8",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "print(faces.target_names)\n",
    "print(faces.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_68oJyLOyATE",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We first take a look at some figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1616541046987,
     "user": {
      "displayName": "Xiaomeng Yan",
      "photoUrl": "",
      "userId": "11420231255337685715"
     },
     "user_tz": 300
    },
    "id": "A8UxLAI3x_Sd",
    "outputId": "76674656-6278-4409-8c32-594090354dd4",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 5,figsize=(10,6))\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[],\n",
    "            xlabel=faces.target_names[faces.target[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czPHQXqiyl4w",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Each image contains [62×47] or nearly 3,000 pixels. We could proceed by simply using each pixel value as a feature, but often it is more effective to use some sort of preprocessor to extract more meaningful features; here we will use PCA to extract 150 fundamental components.\n",
    "\n",
    "Because this is a large dataset, we will use RandomizedPCA (svd_solver='randomized')—it contains a randomized method to approximate the first $N$ principal components much more quickly than the standard PCA estimator, and thus is very useful for high-dimensional data (here, a dimensionality of nearly 3,000). \n",
    "\n",
    "\n",
    "Note that the default selection of \"svd_solver\" is 'auto'. When the input data is larger than 500x500 and the number of components to extract is lower than 80% of the smallest dimension of the data, then the more efficient ‘randomized’ method is enabled automatically for this default selection. (For more information, see: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 931,
     "status": "ok",
     "timestamp": 1616541050304,
     "user": {
      "displayName": "Xiaomeng Yan",
      "photoUrl": "",
      "userId": "11420231255337685715"
     },
     "user_tz": 300
    },
    "id": "TWsfNkRGyq8R",
    "outputId": "3d09d60d-052a-4782-d0fe-342073e2538b",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=150, svd_solver='randomized')\n",
    "pca.fit(faces.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4SzDcdk0lQe",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this case, it can be interesting to visualize the images associated with the first several principal components (these components are technically known as \"eigenvectors,\" so these types of images are often called \"eigenfaces\"). As you can see in this figure, they are as creepy as they sound:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "executionInfo": {
     "elapsed": 1445,
     "status": "ok",
     "timestamp": 1616541053283,
     "user": {
      "displayName": "Xiaomeng Yan",
      "photoUrl": "",
      "userId": "11420231255337685715"
     },
     "user_tz": 300
    },
    "id": "xe_6BwuH0cVR",
    "outputId": "9db4470b-d7d4-48d1-abf5-ed460d253f62",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 8, figsize=(9, 4),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(pca.components_[i].reshape(62, 47), cmap='bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tz3773Vq2Fj0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The results are very interesting, and give us insight into how the images vary.\n",
    "\n",
    "* the first few eigenfaces (from the top left) seem to be associated with the angle of lighting on the face.\n",
    "* later principal vectors seem to be picking out certain features, such as eyes, noses, and lips. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsBQed1OZsVb",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Let's take a look at the cumulative variance of these components to see how much of the data information the projection is preserving. We see that these 100 components account for 91.55% of the variance. That would lead us to believe that using these 100 components, we would recover most of the essential characteristics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1616541057311,
     "user": {
      "displayName": "Xiaomeng Yan",
      "photoUrl": "",
      "userId": "11420231255337685715"
     },
     "user_tz": 300
    },
    "id": "qdIezHCv2GQv",
    "outputId": "61871004-e441-4192-b458-7cac87e755c0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1,151), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "np.cumsum(pca.explained_variance_ratio_)[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-vj2GRn1tq1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Limitation of the linear dimensionality reduction\n",
    "\n",
    "We use the following example to show the limitation of the linear dimensionality reduction:\n",
    "\n",
    "The Swiss Roll data includes three features, which is usually generated by\n",
    "\n",
    "> $x = \\phi cos(\\phi)$  \n",
    "> $y = \\phi csin(\\phi)$  \n",
    "> $z = \\psi$  \n",
    "\n",
    "Each point in the swiss roll data can be represented by two features $(\\phi,\\psi)$. We construct a Swiss Roll dataset with 3000 points and plot it below. The shape of the Swiss Roll data looks like a swiss roll in 3D scatter plot. The color of a point shows its $\\phi$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1616541084081,
     "user": {
      "displayName": "Xiaomeng Yan",
      "photoUrl": "",
      "userId": "11420231255337685715"
     },
     "user_tz": 300
    },
    "id": "n5ZIU-6i2VDK",
    "outputId": "eea2039e-a59c-4670-a132-11ee32412e1d",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "\n",
    "np.random.seed(0) # fix random seed\n",
    "# Generate a Swiss Roll with 3000 samples\n",
    "X, color = datasets.make_swiss_roll(n_samples=3000) \n",
    "\n",
    "# Plot the Swiss Roll\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfNFF6wu69mu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose that in the Swiss Roll data, $\\phi$ is the most important feature in machine learning tasks. For example, points with more similar $\\phi$ are more likely to come from the same group in a classifciation or clustering problem, or a response variable is highly linearly correlated with $\\phi$ in a regression problem. Then we hope that we could recover $\\phi$ by dimensionality reduction methods. Since we know that the relationship between the oriignal features and $\\phi$ are not linear, the linear dimensionality recution methods such as PCA does not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, we construct the first 2 PCs from the Swiss Roll dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "executionInfo": {
     "elapsed": 726,
     "status": "ok",
     "timestamp": 1616541086531,
     "user": {
      "displayName": "Xiaomeng Yan",
      "photoUrl": "",
      "userId": "11420231255337685715"
     },
     "user_tz": 300
    },
    "id": "2Kw5YCu223nz",
    "outputId": "988d6056-6e95-4fb9-d024-51f87b89b3b9",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)  # project from 64 to 2 dimensions\n",
    "Y_projected = pca.fit_transform(X)\n",
    "\n",
    "plt.scatter(Y_projected[:, 0], Y_projected[:, 1],\n",
    "            c=color, cmap=plt.cm.Spectral)\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();\n",
    "plt.title('Projected data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXDiJ1ke8OZF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can see that PCA still keeps the global shape of the Swiss Roll dataset and cannot discover $\\phi$. As a result, we now introduce three non-linear dimensionality reduction methods that focus more on the local information of data than the global information of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_c7tQp1VeSUt",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### T-SNE\n",
    "\n",
    "The idea of T-SNE is to convert affinities/closeness of data points to probabilities. It assumes that \n",
    "> $P_1$(The edge between $i$ and $j$ are selected in the original feature space in an edge sampling process) $\\approx P_2$(The edge between $i$ and $j$ are selected in the projection space in an edge sampling process)\n",
    "\n",
    "Both $P_1 = f_1(\\text{closeness}(\\mathbf{x}^i,\\mathbf{x}^j))$ and $P_2 = f_2(\\text{closeness}(\\mathbf{y}^i,\\mathbf{y}^j))$ are functions of the closeness of data points but have different forms. $f_1$ is built from the Gaussian distribution, while $f_2$ is built from the Student’s t-distribution. Finally, $KL$ divergence (a measure of how one probability distribution is different from a second, reference probability distribution) is used to calculate the different between $P_1$ and $P_2$ on all edges. And $\\mathbf{y}^i$s are generated by minimizing this $KL$ divergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since t-distribution has a heavier tail than the Gaussian distribution,\n",
    "the usage of t-distribution allows t-SNE to be particularly sensitive to local structure in the original feature space and has a few other advantages over existing techniques:\n",
    "1. Reveal the structure at many scales on a single map;\n",
    "\n",
    "2. Reveal data that lie in multiple, different, manifolds or clusters;\n",
    "\n",
    "3. Reduce the tendency to crowd points together at the center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0cM_gUxuic6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Handwritten numbers dataset\n",
    "\n",
    "Handwritten numbers dataset collects a group of images of the hand written numbers from 1 to 10. Each image fits in an 8$\\times$8 pixel box, with the grey level of each pixel recorded in a 8$\\times$8 data matrix. Every matrix is flattened into a vector of 64 numbers, so we have 64 features in this dataset.\n",
    "\n",
    "\n",
    "We use this example to show that t-SNE gives better dimensionality reduction results than other methods when the number of projected features is small (usually 2 or 3). As a result, t-SNE is a popular method to visualize high-dimensional data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8Chh3lcEesi",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We construct the two-dimensional projected features using PCA, and t-SNE respectively, and draw a scatter plot of images according to each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1616541112004,
     "user": {
      "displayName": "Xiaomeng Yan",
      "photoUrl": "",
      "userId": "11420231255337685715"
     },
     "user_tz": 300
    },
    "id": "JfZgtknOFN6N",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()  ## load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdRQBya3lwI8",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are 1797 observations in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ry_mNgZtltnV",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import manifold\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)  \n",
    "PCA_projected = pca.fit_transform(digits.data)\n",
    "\n",
    "# TSNE\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "TSNE_projected = tsne.fit_transform(digits.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqUGKYfekGe5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the above code, we see that the 'init' parameter of TSNE is 'pca'. Usually, when we apply a nonlinear dimensionality reduction method, we first use PCA (or another linear dimensional reduction method) to reduce the method to a $r^*$-dimensional space that $r \\leq r^* < d$. This step can help improve the performance of nonlinear dimensionality reduction methods and make more stable results. The reason comes from two aspects. First, the selected first $r^*$th PCs could contain most of the variance of the original data. The remaining part of variance usually contains a lot of noise and is not useful. Second, the PCs are orthogonal to each other, and using PCA can avoid multicollinearity in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 869
    },
    "executionInfo": {
     "elapsed": 11044,
     "status": "ok",
     "timestamp": 1616528389302,
     "user": {
      "displayName": "Xiaomeng Yan",
      "photoUrl": "",
      "userId": "11420231255337685715"
     },
     "user_tz": 300
    },
    "id": "brFrq6KdmVBI",
    "outputId": "96ce2f85-b9c2-4c54-f340-5d406b4399b1"
   },
   "outputs": [],
   "source": [
    "## draw plots\n",
    "def draw_components(Y_projected, title):\n",
    "    plt.scatter(Y_projected[:, 0], Y_projected[:, 1],\n",
    "            c=digits.target, edgecolor='none', alpha=0.5,\n",
    "            cmap=plt.get_cmap('rainbow', 10))\n",
    "    plt.xlabel('component 1')\n",
    "    plt.ylabel('component 2')\n",
    "    plt.title(title)\n",
    "    plt.colorbar();\n",
    "draw_components(PCA_projected, 'PCA');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "draw_components(TSNE_projected, 'T-SNE');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pc8gAX3Ros84",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We observe that T-SNE can separate the images with different numbers best.\n",
    "\n",
    "We now cluster all images into 10 groups and expect that each group contains one of numbers from 1 to 10. We compare the clustering results of k-means methods built on the original 64 features and the two-dimensional features constructed by different dimensionality reduction methods respectively. With the true labels of numbers, we use the ARI metric to evaluate their clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "executionInfo": {
     "elapsed": 1784,
     "status": "ok",
     "timestamp": 1616528393018,
     "user": {
      "displayName": "Xiaomeng Yan",
      "photoUrl": "",
      "userId": "11420231255337685715"
     },
     "user_tz": 300
    },
    "id": "e4b8QkrkpYrU",
    "outputId": "f660f6b7-43d5-47ed-ebfd-e33b10e3d896",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# For k-means with original features\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "# \"random_state=100\" is to set a random number.\n",
    "cluster_ori = KMeans(n_clusters=10,random_state=100).fit_predict(digits.data)\n",
    "cluster_PCA = KMeans(n_clusters=10,random_state=100).fit_predict(PCA_projected)\n",
    "cluster_TSNE = KMeans(n_clusters=10,random_state=100).fit_predict(TSNE_projected)\n",
    "\n",
    "# caluclate ARI of different mehtods\n",
    "ari_ori = metrics.adjusted_rand_score(digits.target, cluster_ori)\n",
    "ari_PCA = metrics.adjusted_rand_score(digits.target, cluster_PCA)\n",
    "ari_TSNE = metrics.adjusted_rand_score(digits.target, cluster_TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Compare the results\n",
    "name_list = ['Original ','PCA','TSNE']\n",
    "num_list = [ari_ori,ari_PCA,ari_TSNE]\n",
    "plt.bar(range(len(num_list)), num_list, color = \"b\",tick_label=name_list)\n",
    "plt.xlabel(\"ARI\")\n",
    "plt.title(\"Comparison of Clustering Results\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqOo4ApbEJZd",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can see that for this dataset, TSNE performs much better than other methods in clustering the images."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "k_nearest_neighbor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
